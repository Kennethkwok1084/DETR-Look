[BEGIN] 2026/1/7 15:37:38
ğŸš€ DETR è®­ç»ƒï¼ˆtransformers + ä¼˜åŒ–æ•°æ®åŠ è½½ï¼‰
================================================================================
è¾“å‡ºç›®å½•: outputs/overfit_5_v4
è®¾å¤‡: cuda
Batch Size: 1 | Workers: 0
å›¾åƒå°ºå¯¸: min=800, max=1333
æ¢¯åº¦è£å‰ª: clip_max_norm=0.1
================================================================================
loading annotations into memory...
^[[M`J<Done (t=3.58s)
creating index...
index created!
ğŸ“‹ é»‘åå•è¿‡æ»¤: 2 å¼ æŸåå›¾åƒå·²è·³è¿‡
ğŸ“Š ä½¿ç”¨è®­ç»ƒå­é›†: 5 å¼ å›¾åƒ
ğŸ“¦ æ„å»ºæ¨¡å‹: num_classes=3
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.4.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.4.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.4.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.4.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.4.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.5.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.5.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.5.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.5.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.5.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.5.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.5.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.5.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.5.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/detr/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']
- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:
- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([4]) in the model instantiated
- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([4, 256]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
================================================================================
ğŸ¯ å¼€å§‹è®­ç»ƒ
================================================================================
================================================================================
Epoch [1/300] å®Œæˆ | è€—æ—¶: 2.3s
è®­ç»ƒ Loss: 2.7956
================================================================================
================================================================================
Epoch [2/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 2.9004
================================================================================
================================================================================
Epoch [3/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.7544
================================================================================
================================================================================
Epoch [4/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 2.7570
================================================================================
================================================================================
Epoch [5/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 2.6317
================================================================================
================================================================================
Epoch [6/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 3.0966
================================================================================
================================================================================
Epoch [7/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 2.7796
================================================================================
================================================================================
Epoch [8/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 2.3812
================================================================================
================================================================================
Epoch [9/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.2400
================================================================================
================================================================================
Epoch [10/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 2.5768
================================================================================
================================================================================
Epoch [11/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.4459
================================================================================
================================================================================
Epoch [12/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 2.3565
================================================================================
================================================================================
Epoch [13/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.3034
================================================================================
================================================================================
Epoch [14/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.3872
================================================================================
================================================================================
Epoch [15/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.2800
================================================================================
================================================================================
Epoch [16/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.3351
================================================================================
================================================================================
Epoch [17/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.2111
================================================================================
================================================================================
Epoch [18/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.3234
================================================================================
================================================================================
Epoch [19/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.9784
================================================================================
================================================================================
Epoch [20/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.9172
================================================================================
================================================================================
Epoch [21/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.0820
================================================================================
================================================================================
Epoch [22/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.0264
================================================================================
================================================================================
Epoch [23/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 2.1757
================================================================================
================================================================================
Epoch [24/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.2742
================================================================================
================================================================================
Epoch [25/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.4853
================================================================================
================================================================================
Epoch [26/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.7295
================================================================================
================================================================================
Epoch [27/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.7020
================================================================================
================================================================================
Epoch [28/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.1747
================================================================================
================================================================================
Epoch [29/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.9888
================================================================================
================================================================================
Epoch [30/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.9573
================================================================================
================================================================================
Epoch [31/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.9432
================================================================================
================================================================================
Epoch [32/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.8788
================================================================================
================================================================================
Epoch [33/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.8122
================================================================================
================================================================================
Epoch [34/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.9067
================================================================================
================================================================================
Epoch [35/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.8440
================================================================================
================================================================================
Epoch [36/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7654
================================================================================
================================================================================
Epoch [37/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7886
================================================================================
================================================================================
Epoch [38/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.9082
================================================================================
================================================================================
Epoch [39/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.8178
================================================================================
================================================================================
Epoch [40/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7174
================================================================================
================================================================================
Epoch [41/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6810
================================================================================
================================================================================
Epoch [42/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7036
================================================================================
================================================================================
Epoch [43/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7491
================================================================================
================================================================================
Epoch [44/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.6574
================================================================================
================================================================================
Epoch [45/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7215
================================================================================
================================================================================
Epoch [46/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6789
================================================================================
================================================================================
Epoch [47/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5936
================================================================================
================================================================================
Epoch [48/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7192
================================================================================
================================================================================
Epoch [49/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6747
================================================================================
================================================================================
Epoch [50/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6114
================================================================================
================================================================================
Epoch [51/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.9429
================================================================================
================================================================================
Epoch [52/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.8842
================================================================================
================================================================================
Epoch [53/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.0156
================================================================================
================================================================================
Epoch [54/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.0884
================================================================================
================================================================================
Epoch [55/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7977
================================================================================
================================================================================
Epoch [56/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.8709
================================================================================
================================================================================
Epoch [57/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7402
================================================================================
================================================================================
Epoch [58/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.8871
================================================================================
================================================================================
Epoch [59/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7232
================================================================================
================================================================================
Epoch [60/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5795
================================================================================
================================================================================
Epoch [61/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6080
================================================================================
================================================================================
Epoch [62/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5309
================================================================================
================================================================================
Epoch [63/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5055
================================================================================
================================================================================
Epoch [64/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4689
================================================================================
================================================================================
Epoch [65/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.5278
================================================================================
================================================================================
Epoch [66/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.6070
================================================================================
================================================================================
Epoch [67/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.5097
================================================================================
================================================================================
Epoch [68/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4581
================================================================================
================================================================================
Epoch [69/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4351
================================================================================
================================================================================
Epoch [70/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6077
================================================================================
================================================================================
Epoch [71/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6617
================================================================================
================================================================================
Epoch [72/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5274
================================================================================
================================================================================
Epoch [73/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5731
================================================================================
================================================================================
Epoch [74/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.5840
================================================================================
================================================================================
Epoch [75/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5009
================================================================================
================================================================================
Epoch [76/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5353
================================================================================
================================================================================
Epoch [77/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.6019
================================================================================
================================================================================
Epoch [78/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7257
================================================================================
================================================================================
Epoch [79/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7855
================================================================================
================================================================================
Epoch [80/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.7371
================================================================================
================================================================================
Epoch [81/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.8201
================================================================================
================================================================================
Epoch [82/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6275
================================================================================
================================================================================
Epoch [83/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.7354
================================================================================
================================================================================
Epoch [84/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5190
================================================================================
================================================================================
Epoch [85/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.6615
================================================================================
================================================================================
Epoch [86/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.5228
================================================================================
================================================================================
Epoch [87/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.4118
================================================================================
================================================================================
Epoch [88/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5620
================================================================================
================================================================================
Epoch [89/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5158
================================================================================
================================================================================
Epoch [90/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6034
================================================================================
================================================================================
Epoch [91/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4413
================================================================================
================================================================================
Epoch [92/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5741
================================================================================
================================================================================
Epoch [93/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3569
================================================================================
================================================================================
Epoch [94/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4016
================================================================================
================================================================================
Epoch [95/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.4734
================================================================================
================================================================================
Epoch [96/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4117
================================================================================
================================================================================
Epoch [97/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6721
================================================================================
================================================================================
Epoch [98/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.3453
================================================================================
================================================================================
Epoch [99/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5454
================================================================================
================================================================================
Epoch [100/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.8047
================================================================================
================================================================================
Epoch [101/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5662
================================================================================
================================================================================
Epoch [102/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4990
================================================================================
================================================================================
Epoch [103/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4468
================================================================================
================================================================================
Epoch [104/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3547
================================================================================
================================================================================
Epoch [105/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.3112
================================================================================
================================================================================
Epoch [106/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4735
================================================================================
================================================================================
Epoch [107/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4115
================================================================================
================================================================================
Epoch [108/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5193
================================================================================
================================================================================
Epoch [109/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3045
================================================================================
================================================================================
Epoch [110/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3440
================================================================================
================================================================================
Epoch [111/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4017
================================================================================
================================================================================
Epoch [112/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5124
================================================================================
================================================================================
Epoch [113/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3464
================================================================================
================================================================================
Epoch [114/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3315
================================================================================
================================================================================
Epoch [115/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3363
================================================================================
================================================================================
Epoch [116/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2317
================================================================================
================================================================================
Epoch [117/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3276
================================================================================
================================================================================
Epoch [118/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.3208
================================================================================
================================================================================
Epoch [119/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3252
================================================================================
================================================================================
Epoch [120/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3064
================================================================================
================================================================================
Epoch [121/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.3182
================================================================================
================================================================================
Epoch [122/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3641
================================================================================
================================================================================
Epoch [123/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2328
================================================================================
================================================================================
Epoch [124/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4809
================================================================================
================================================================================
Epoch [125/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3334
================================================================================
================================================================================
Epoch [126/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.3626
================================================================================
================================================================================
Epoch [127/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5290
================================================================================
================================================================================
Epoch [128/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4623
================================================================================
================================================================================
Epoch [129/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4849
================================================================================
================================================================================
Epoch [130/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4825
================================================================================
================================================================================
Epoch [131/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.3932
================================================================================
================================================================================
Epoch [132/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2888
================================================================================
================================================================================
Epoch [133/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.3525
================================================================================
================================================================================
Epoch [134/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4470
================================================================================
================================================================================
Epoch [135/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2811
================================================================================
================================================================================
Epoch [136/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2142
================================================================================
================================================================================
Epoch [137/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1844
================================================================================
================================================================================
Epoch [138/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1881
================================================================================
================================================================================
Epoch [139/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2083
================================================================================
================================================================================
Epoch [140/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2950
================================================================================
================================================================================
Epoch [141/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1944
================================================================================
================================================================================
Epoch [142/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2692
================================================================================
================================================================================
Epoch [143/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2598
================================================================================
================================================================================
Epoch [144/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2415
================================================================================
================================================================================
Epoch [145/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.3724
================================================================================
================================================================================
Epoch [146/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6959
================================================================================
================================================================================
Epoch [147/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 3.1901
================================================================================
================================================================================
Epoch [148/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 2.1598
================================================================================
================================================================================
Epoch [149/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.6766
================================================================================
================================================================================
Epoch [150/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4332
================================================================================
================================================================================
Epoch [151/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4471
================================================================================
================================================================================
Epoch [152/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2905
================================================================================
================================================================================
Epoch [153/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3735
================================================================================
================================================================================
Epoch [154/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4512
================================================================================
================================================================================
Epoch [155/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5115
================================================================================
================================================================================
Epoch [156/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4996
================================================================================
================================================================================
Epoch [157/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4446
================================================================================
================================================================================
Epoch [158/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3359
================================================================================
================================================================================
Epoch [159/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4219
================================================================================
================================================================================
Epoch [160/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3011
================================================================================
================================================================================
Epoch [161/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1874
================================================================================
================================================================================
Epoch [162/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2305
================================================================================
================================================================================
Epoch [163/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1700
================================================================================
================================================================================
Epoch [164/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2109
================================================================================
================================================================================
Epoch [165/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2539
================================================================================
================================================================================
Epoch [166/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2791
================================================================================
================================================================================
Epoch [167/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2232
================================================================================
================================================================================
Epoch [168/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0946
================================================================================
================================================================================
Epoch [169/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0200
================================================================================
================================================================================
Epoch [170/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.0033
================================================================================
================================================================================
Epoch [171/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1875
================================================================================
================================================================================
Epoch [172/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1841
================================================================================
================================================================================
Epoch [173/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1848
================================================================================
================================================================================
Epoch [174/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1198
================================================================================
================================================================================
Epoch [175/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.0695
================================================================================
================================================================================
Epoch [176/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1390
================================================================================
================================================================================
Epoch [177/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0727
================================================================================
================================================================================
Epoch [178/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1611
================================================================================
================================================================================
Epoch [179/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.0374
================================================================================
================================================================================
Epoch [180/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1336
================================================================================
================================================================================
Epoch [181/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1420
================================================================================
================================================================================
Epoch [182/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1750
================================================================================
================================================================================
Epoch [183/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1368
================================================================================
================================================================================
Epoch [184/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3540
================================================================================
================================================================================
Epoch [185/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3392
================================================================================
================================================================================
Epoch [186/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2953
================================================================================
================================================================================
Epoch [187/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1971
================================================================================
================================================================================
Epoch [188/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2487
================================================================================
================================================================================
Epoch [189/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1595
================================================================================
================================================================================
Epoch [190/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.0374
================================================================================
================================================================================
Epoch [191/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0863
================================================================================
================================================================================
Epoch [192/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1807
================================================================================
================================================================================
Epoch [193/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2110
================================================================================
================================================================================
Epoch [194/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1778
================================================================================
================================================================================
Epoch [195/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1476
================================================================================
================================================================================
Epoch [196/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1761
================================================================================
================================================================================
Epoch [197/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.0036
================================================================================
================================================================================
Epoch [198/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1005
================================================================================
================================================================================
Epoch [199/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3290
================================================================================
================================================================================
Epoch [200/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1866
================================================================================
================================================================================
Epoch [201/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.3676
================================================================================
================================================================================
Epoch [202/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2915
================================================================================
================================================================================
Epoch [203/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2575
================================================================================
================================================================================
Epoch [204/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.3660
================================================================================
================================================================================
Epoch [205/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.3924
================================================================================
================================================================================
Epoch [206/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3673
================================================================================
================================================================================
Epoch [207/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3984
================================================================================
================================================================================
Epoch [208/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.2908
================================================================================
================================================================================
Epoch [209/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3349
================================================================================
================================================================================
Epoch [210/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2527
================================================================================
================================================================================
Epoch [211/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2254
================================================================================
================================================================================
Epoch [212/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1745
================================================================================
================================================================================
Epoch [213/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0963
================================================================================
================================================================================
Epoch [214/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.1104
================================================================================
================================================================================
Epoch [215/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0716
================================================================================
================================================================================
Epoch [216/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 0.9717
================================================================================
================================================================================
Epoch [217/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1420
================================================================================
================================================================================
Epoch [218/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.0556
================================================================================
================================================================================
Epoch [219/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 0.9826
================================================================================
================================================================================
Epoch [220/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2369
================================================================================
================================================================================
Epoch [221/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.1457
================================================================================
================================================================================
Epoch [222/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1473
================================================================================
================================================================================
Epoch [223/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1298
================================================================================
================================================================================
Epoch [224/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1055
================================================================================
================================================================================
Epoch [225/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0393
================================================================================
================================================================================
Epoch [226/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1001
================================================================================
================================================================================
Epoch [227/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.0408
================================================================================
================================================================================
Epoch [228/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0780
================================================================================
================================================================================
Epoch [229/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.1351
================================================================================
================================================================================
Epoch [230/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.0401
================================================================================
================================================================================
Epoch [231/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.1854
================================================================================
================================================================================
Epoch [232/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.1770
================================================================================
================================================================================
Epoch [233/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.1096
================================================================================
================================================================================
Epoch [234/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1875
================================================================================
================================================================================
Epoch [235/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.4041
================================================================================
================================================================================
Epoch [236/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.0374
================================================================================
================================================================================
Epoch [237/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1297
================================================================================
================================================================================
Epoch [238/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1981
================================================================================
================================================================================
Epoch [239/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2561
================================================================================
================================================================================
Epoch [240/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1360
================================================================================
================================================================================
Epoch [241/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.0954
================================================================================
================================================================================
Epoch [242/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.0305
================================================================================
================================================================================
Epoch [243/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.0397
================================================================================
================================================================================
Epoch [244/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1413
================================================================================
================================================================================
Epoch [245/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2009
================================================================================
================================================================================
Epoch [246/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1079
================================================================================
================================================================================
Epoch [247/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.0897
================================================================================
================================================================================
Epoch [248/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.0861
================================================================================
================================================================================
Epoch [249/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0567
================================================================================
================================================================================
Epoch [250/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0494
================================================================================
================================================================================
Epoch [251/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 0.9847
================================================================================
================================================================================
Epoch [252/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 0.9221
================================================================================
================================================================================
Epoch [253/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 0.9355
================================================================================
================================================================================
Epoch [254/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 0.9624
================================================================================
================================================================================
Epoch [255/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 0.9928
================================================================================
================================================================================
Epoch [256/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1032
================================================================================
================================================================================
Epoch [257/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2003
================================================================================
================================================================================
Epoch [258/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0369
================================================================================
================================================================================
Epoch [259/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0474
================================================================================
================================================================================
Epoch [260/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0959
================================================================================
================================================================================
Epoch [261/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0274
================================================================================
================================================================================
Epoch [262/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 0.9808
================================================================================
================================================================================
Epoch [263/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.0689
================================================================================
================================================================================
Epoch [264/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.1103
================================================================================
================================================================================
Epoch [265/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 0.9914
================================================================================
================================================================================
Epoch [266/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 0.9618
================================================================================
================================================================================
Epoch [267/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.1291
================================================================================
================================================================================
Epoch [268/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.0417
================================================================================
================================================================================
Epoch [269/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.0856
================================================================================
================================================================================
Epoch [270/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.1087
================================================================================
================================================================================
Epoch [271/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.1342
================================================================================
================================================================================
Epoch [272/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.1103
================================================================================
================================================================================
Epoch [273/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.3137
================================================================================
================================================================================
Epoch [274/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.0900
================================================================================
================================================================================
Epoch [275/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1171
================================================================================
================================================================================
Epoch [276/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2294
================================================================================
================================================================================
Epoch [277/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2019
================================================================================
================================================================================
Epoch [278/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3316
================================================================================
================================================================================
Epoch [279/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.5646
================================================================================
================================================================================
Epoch [280/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6707
================================================================================
================================================================================
Epoch [281/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 2.4891
================================================================================
================================================================================
Epoch [282/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 2.3715
================================================================================
================================================================================
Epoch [283/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.5412
================================================================================
================================================================================
Epoch [284/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.6070
================================================================================
================================================================================
Epoch [285/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4424
================================================================================
================================================================================
Epoch [286/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.4088
================================================================================
================================================================================
Epoch [287/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.3684
================================================================================
================================================================================
Epoch [288/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2908
================================================================================
================================================================================
Epoch [289/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2502
================================================================================
================================================================================
Epoch [290/300] å®Œæˆ | è€—æ—¶: 0.5s
è®­ç»ƒ Loss: 1.3439
================================================================================
================================================================================
Epoch [291/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3136
================================================================================
================================================================================
Epoch [292/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1214
================================================================================
================================================================================
Epoch [293/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.2284
================================================================================
================================================================================
Epoch [294/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.1434
================================================================================
================================================================================
Epoch [295/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1657
================================================================================
================================================================================
Epoch [296/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.2320
================================================================================
================================================================================
Epoch [297/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.1423
================================================================================
================================================================================
Epoch [298/300] å®Œæˆ | è€—æ—¶: 0.6s
è®­ç»ƒ Loss: 1.3744
================================================================================
================================================================================
Epoch [299/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.3304
================================================================================
================================================================================
Epoch [300/300] å®Œæˆ | è€—æ—¶: 0.7s
è®­ç»ƒ Loss: 1.3356
================================================================================
âœ… è®­ç»ƒå®Œæˆï¼
(detr) root@autodl-container-99ea4bb89d-165cc1cf:~/autodl-tmp/detr# `J<

[END] 2026/1/7 15:45:54
