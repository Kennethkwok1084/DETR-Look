#!/usr/bin/env python3
"""
æ¨¡å‹checkpointä¿å­˜ä¸åŠ è½½
æ”¯æŒå®Œæ•´è®­ç»ƒçŠ¶æ€ï¼šoptimizer, scheduler, AMP scaler, epoch/iter, best metric, RNGçŠ¶æ€
"""

import random
import torch
import numpy as np
from pathlib import Path
from typing import Any, Dict, Optional


def save_checkpoint(
    model: torch.nn.Module,
    optimizer: torch.optim.Optimizer,
    epoch: int,
    step: int,
    metrics: Dict[str, Any],
    output_dir: Path,
    filename: str = "checkpoint.pth",
    is_best: bool = False,
    scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,
    scaler: Optional[torch.cuda.amp.GradScaler] = None,
    best_metric: Optional[float] = None,
    best_loss: Optional[float] = None,
    save_rng_state: bool = True,
):
    """
    ä¿å­˜å®Œæ•´checkpointçŠ¶æ€
    
    Args:
        model: æ¨¡å‹
        optimizer: ä¼˜åŒ–å™¨
        epoch: å½“å‰epoch
        step: å½“å‰step
        metrics: å½“å‰æŒ‡æ ‡
        output_dir: è¾“å‡ºç›®å½•
        filename: æ–‡ä»¶å
        is_best: æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå¯é€‰ï¼‰
        scaler: AMP GradScalerï¼ˆå¯é€‰ï¼‰
        best_metric: æœ€ä½³æŒ‡æ ‡å€¼/mAPï¼ˆå¯é€‰ï¼‰
        best_loss: æœ€ä½³æŸå¤±å€¼ï¼ˆå¯é€‰ï¼‰
        save_rng_state: æ˜¯å¦ä¿å­˜RNGçŠ¶æ€ï¼ˆå¯é€‰ä½†æ¨èï¼‰
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # åŸºç¡€çŠ¶æ€
    checkpoint = {
        'epoch': epoch,
        'step': step,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'metrics': metrics,
    }
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
    if scheduler is not None:
        checkpoint['scheduler_state_dict'] = scheduler.state_dict()
    
    # AMP scalerçŠ¶æ€
    if scaler is not None:
        checkpoint['scaler_state_dict'] = scaler.state_dict()
    
    # æœ€ä½³æŒ‡æ ‡
    if best_metric is not None:
        checkpoint['best_metric'] = best_metric
    if best_loss is not None:
        checkpoint['best_loss'] = best_loss
    
    # RNGçŠ¶æ€ï¼ˆç”¨äºå®Œå…¨å¯å¤ç°ï¼‰
    if save_rng_state:
        checkpoint['rng_state'] = {
            'python': random.getstate(),
            'numpy': np.random.get_state(),
            'torch': torch.get_rng_state(),
        }
        if torch.cuda.is_available():
            checkpoint['rng_state']['cuda'] = torch.cuda.get_rng_state_all()
    
    # ä¿å­˜
    save_path = output_dir / filename
    torch.save(checkpoint, save_path)
    print(f"ğŸ’¾ Checkpoint å·²ä¿å­˜: {save_path}")
    print(f"   Epoch: {epoch}, Step: {step}, Metrics: {metrics}")
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if is_best:
        best_path = output_dir / "best.pth"
        torch.save(checkpoint, best_path)
        print(f"ğŸ† æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_path}")
        if best_metric is not None:
            print(f"   æœ€ä½³æŒ‡æ ‡: {best_metric:.4f}")


def load_checkpoint(
    checkpoint_path: Path,
    model: torch.nn.Module,
    optimizer: Optional[torch.optim.Optimizer] = None,
    scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,
    scaler: Optional[torch.cuda.amp.GradScaler] = None,
    device: str = 'cpu',
    restore_rng_state: bool = True,
) -> Dict[str, Any]:
    """
    åŠ è½½å®Œæ•´checkpointçŠ¶æ€
    
    Args:
        checkpoint_path: checkpointæ–‡ä»¶è·¯å¾„
        model: æ¨¡å‹
        optimizer: ä¼˜åŒ–å™¨ï¼ˆå¯é€‰ï¼‰
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå¯é€‰ï¼‰
        scaler: AMP GradScalerï¼ˆå¯é€‰ï¼‰
        device: è®¾å¤‡
        restore_rng_state: æ˜¯å¦æ¢å¤RNGçŠ¶æ€
    
    Returns:
        checkpointå­—å…¸
    """
    print(f"ğŸ“‚ åŠ è½½checkpoint: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # åŠ è½½æ¨¡å‹å‚æ•°
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
    if optimizer is not None and 'optimizer_state_dict' in checkpoint:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        print(f"   âœ“ ä¼˜åŒ–å™¨çŠ¶æ€å·²æ¢å¤")
    
    # åŠ è½½å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
    if scheduler is not None and 'scheduler_state_dict' in checkpoint:
        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        print(f"   âœ“ å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€å·²æ¢å¤")
    
    # åŠ è½½AMP scalerçŠ¶æ€
    if scaler is not None and 'scaler_state_dict' in checkpoint:
        scaler.load_state_dict(checkpoint['scaler_state_dict'])
        print(f"   âœ“ AMP ScalerçŠ¶æ€å·²æ¢å¤")
    
    # æ¢å¤RNGçŠ¶æ€
    if restore_rng_state and 'rng_state' in checkpoint:
        rng_state = checkpoint['rng_state']
        random.setstate(rng_state['python'])
        np.random.set_state(rng_state['numpy'])
        torch.set_rng_state(rng_state['torch'])
        if torch.cuda.is_available() and 'cuda' in rng_state:
            torch.cuda.set_rng_state_all(rng_state['cuda'])
        print(f"   âœ“ RNGçŠ¶æ€å·²æ¢å¤ï¼ˆå®Œå…¨å¯å¤ç°ï¼‰")
    
    # æ‰“å°æ¢å¤ä¿¡æ¯
    epoch = checkpoint.get('epoch', 0)
    step = checkpoint.get('step', 0)
    best_metric = checkpoint.get('best_metric')
    best_loss = checkpoint.get('best_loss')
    
    print(f"âœ… CheckpointåŠ è½½æˆåŠŸ")
    print(f"   Epoch: {epoch}, Step: {step}")
    if best_metric is not None:
        print(f"   æœ€ä½³æŒ‡æ ‡ (mAP): {best_metric:.4f}")
    if best_loss is not None:
        print(f"   æœ€ä½³æŸå¤±: {best_loss:.4f}")
    
    return checkpoint
