#!/usr/bin/env python3
"""
æ¨¡å‹checkpointä¿å­˜ä¸åŠ è½½
"""

import torch
from pathlib import Path
from typing import Any, Dict, Optional


def save_checkpoint(
    model: torch.nn.Module,
    optimizer: torch.optim.Optimizer,
    epoch: int,
    step: int,
    metrics: Dict[str, Any],
    output_dir: Path,
    filename: str = "checkpoint.pth",
    is_best: bool = False,
):
    """
    ä¿å­˜checkpoint
    
    Args:
        model: æ¨¡å‹
        optimizer: ä¼˜åŒ–å™¨
        epoch: å½“å‰epoch
        step: å½“å‰step
        metrics: å½“å‰æŒ‡æ ‡
        output_dir: è¾“å‡ºç›®å½•
        filename: æ–‡ä»¶å
        is_best: æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    checkpoint = {
        'epoch': epoch,
        'step': step,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'metrics': metrics,
    }
    
    save_path = output_dir / filename
    torch.save(checkpoint, save_path)
    print(f"ğŸ’¾ Checkpoint å·²ä¿å­˜: {save_path}")
    
    if is_best:
        best_path = output_dir / "best.pth"
        torch.save(checkpoint, best_path)
        print(f"ğŸ† æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_path}")


def load_checkpoint(
    checkpoint_path: Path,
    model: torch.nn.Module,
    optimizer: Optional[torch.optim.Optimizer] = None,
    device: str = 'cpu',
) -> Dict[str, Any]:
    """
    åŠ è½½checkpoint
    
    Args:
        checkpoint_path: checkpointæ–‡ä»¶è·¯å¾„
        model: æ¨¡å‹
        optimizer: ä¼˜åŒ–å™¨ï¼ˆå¯é€‰ï¼‰
        device: è®¾å¤‡
    
    Returns:
        checkpointå­—å…¸
    """
    print(f"ğŸ“‚ åŠ è½½checkpoint: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    model.load_state_dict(checkpoint['model_state_dict'])
    
    if optimizer is not None and 'optimizer_state_dict' in checkpoint:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    
    print(f"âœ… CheckpointåŠ è½½æˆåŠŸ (Epoch {checkpoint.get('epoch', 0)}, Step {checkpoint.get('step', 0)})")
    
    return checkpoint
