#!/usr/bin/env python3
"""
Deformable DETR æ¨¡å‹å°è£…
åŸºäºå®˜æ–¹å®ç°ï¼Œé€‚é…é¡¹ç›®è®­ç»ƒæµç¨‹
æä¾› HuggingFace å…¼å®¹æ¥å£
"""

import sys
import os
from pathlib import Path

import torch
import torch.nn as nn

# æ·»åŠ  third_party è·¯å¾„åˆ° sys.path
THIRD_PARTY_PATH = Path(__file__).parent.parent / "third_party" / "deformable_detr"
if str(THIRD_PARTY_PATH) not in sys.path:
    sys.path.insert(0, str(THIRD_PARTY_PATH))

# ç¼“å­˜å¯¼å…¥çš„æ¨¡å—ï¼Œé¿å…é‡å¤æ‰§è¡Œ
_DEFORMABLE_MODULES = None

def _lazy_import_deformable_detr():
    """å»¶è¿Ÿå¯¼å…¥ Deformable DETR æ¨¡å—ï¼ˆä»…æ‰§è¡Œä¸€æ¬¡ï¼‰"""
    global _DEFORMABLE_MODULES
    
    if _DEFORMABLE_MODULES is not None:
        return _DEFORMABLE_MODULES
    
    import sys
    import importlib
    
    # ä¿å­˜å¹¶ä¸´æ—¶ä¿®æ”¹ sys.path
    # ä¿ç•™è™šæ‹Ÿç¯å¢ƒè·¯å¾„ï¼ˆsite-packagesï¼‰ä½†ç§»é™¤é¡¹ç›®æ ¹ç›®å½•
    original_path = sys.path.copy()
    venv_paths = [p for p in original_path if 'site-packages' in p or 'lib' in p.lower()]
    sys.path = [str(THIRD_PARTY_PATH)] + venv_paths
    
    # åˆ é™¤å·²åŠ è½½çš„é¡¹ç›® models åŒ…ï¼Œå¼ºåˆ¶ä» third_party é‡æ–°å¯¼å…¥
    modules_to_clear = [k for k in list(sys.modules.keys()) 
                       if (k == 'models' or k.startswith('models.')) 
                       and not k.startswith('models.deformable_detr_model')]
    for k in modules_to_clear:
        sys.modules.pop(k, None)
    
    try:
        # ç°åœ¨å¯ä»¥å¯¼å…¥ models.deformable_detr (æ¥è‡ªthird_party/deformable_detr/models/)
        import models.deformable_detr as deformable_detr_module
        import models.backbone as backbone_module
        import models.matcher as matcher_module  
        import models.deformable_transformer as transformer_module
        import util.misc as misc_module
        
        _DEFORMABLE_MODULES = {
            'DeformableDETR': deformable_detr_module.DeformableDETR,
            'SetCriterion': deformable_detr_module.SetCriterion,
            'MLP': deformable_detr_module.MLP,
            'build_backbone': backbone_module.build_backbone,
            'build_matcher': matcher_module.build_matcher,
            'build_deforamble_transformer': transformer_module.build_deforamble_transformer,
            'NestedTensor': misc_module.NestedTensor,
            'nested_tensor_from_tensor_list': misc_module.nested_tensor_from_tensor_list,
        }
        return _DEFORMABLE_MODULES
    except Exception as e:
        raise ImportError(
            f"æ— æ³•å¯¼å…¥ Deformable DETR æ¨¡å—ã€‚\n"
            f"è¯·ç¡®ä¿ï¼š\n"
            f"1. å·²å°†å®˜æ–¹æºç å¤åˆ¶åˆ° {THIRD_PARTY_PATH}\n"
            f"2. å·²ç¼–è¯‘ CUDA æ‰©å±•ï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰\n"
            f"é”™è¯¯è¯¦æƒ…: {e}"
        )
    finally:
        # æ¢å¤åŸå§‹ sys.path
        sys.path = original_path


class DeformableDETRModel(nn.Module):
    """
    Deformable DETR æ¨¡å‹å°è£…
    é€‚é…ç°æœ‰è®­ç»ƒæµç¨‹ï¼Œæä¾›ç»Ÿä¸€æ¥å£
    """
    
    def __init__(self, config: dict):
        """
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«æ¨¡å‹å‚æ•°
        """
        super().__init__()
        
        # å»¶è¿Ÿå¯¼å…¥æ¨¡å—
        modules = _lazy_import_deformable_detr()
        DeformableDETR = modules['DeformableDETR']
        SetCriterion = modules['SetCriterion']
        build_backbone = modules['build_backbone']
        build_matcher = modules['build_matcher']
        build_deforamble_transformer = modules['build_deforamble_transformer']
        
        self.config = config
        model_config = config['model']
        
        # è·å–ç±»åˆ«æ•°
        num_classes = config['dataset']['num_classes']
        
        # æ„å»ºæ¨¡å‹å‚æ•°
        args = self._build_args(model_config, num_classes)
        
        # æ„å»º backbone
        print(f"ğŸ”¨ æ„å»º Deformable DETR backbone...")
        backbone = build_backbone(args)
        
        # æ„å»º transformer
        print(f"ğŸ”¨ æ„å»º Deformable Transformer...")
        transformer = build_deforamble_transformer(args)
        
        # æ„å»º Deformable DETR æ¨¡å‹
        print(f"ğŸ”¨ æ„å»º Deformable DETR æ¨¡å‹: {num_classes} ä¸ªç±»åˆ«")
        self.model = DeformableDETR(
            backbone,
            transformer,
            num_classes=num_classes,
            num_queries=args.num_queries,
            num_feature_levels=args.num_feature_levels,
            aux_loss=args.aux_loss,
            with_box_refine=args.with_box_refine,
            two_stage=args.two_stage,
        )
        
        # æ„å»º matcher å’Œ criterion
        matcher = build_matcher(args)
        weight_dict = {
            'loss_ce': args.cls_loss_coef,
            'loss_bbox': args.bbox_loss_coef,
            'loss_giou': args.giou_loss_coef,
        }
        
        # è¾…åŠ©æŸå¤±æƒé‡
        if args.aux_loss:
            aux_weight_dict = {}
            for i in range(args.dec_layers - 1):
                aux_weight_dict.update({k + f'_{i}': v for k, v in weight_dict.items()})
            aux_weight_dict.update({k + f'_enc': v for k, v in weight_dict.items()})
            weight_dict.update(aux_weight_dict)
        
        losses = ['labels', 'boxes', 'cardinality']
        
        self.criterion = SetCriterion(
            num_classes,
            matcher=matcher,
            weight_dict=weight_dict,
            losses=losses,
            focal_alpha=args.focal_alpha
        )
        
        print(f"âœ… Deformable DETR æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
    def _build_args(self, model_config, num_classes):
        """æ„å»ºæ¨¡å‹å‚æ•°å¯¹è±¡"""
        class Args:
            pass
        
        args = Args()
        
        # Backbone
        args.backbone = model_config.get('backbone', 'resnet50')
        args.dilation = model_config.get('dilation', False)
        args.position_embedding = model_config.get('position_embedding', 'sine')
        args.position_embedding_scale = model_config.get('position_embedding_scale', 2 * 3.14159265359)
        args.num_feature_levels = model_config.get('num_feature_levels', 4)
        args.lr_backbone = model_config.get('lr_backbone', 1e-5)  # æ·»åŠ  lr_backbone
        args.masks = model_config.get('masks', False)  # æ·»åŠ  masks (åˆ†å‰²ä»»åŠ¡)
        
        # Transformer
        args.enc_layers = model_config.get('enc_layers', 6)
        args.dec_layers = model_config.get('dec_layers', 6)
        args.dim_feedforward = model_config.get('dim_feedforward', 1024)
        args.hidden_dim = model_config.get('hidden_dim', 256)
        args.dropout = model_config.get('dropout', 0.1)
        args.nheads = model_config.get('nheads', 8)
        args.num_queries = model_config.get('num_queries', 300)
        args.dec_n_points = model_config.get('dec_n_points', 4)
        args.enc_n_points = model_config.get('enc_n_points', 4)
        
        # Deformable DETR ç‰¹æœ‰
        args.two_stage = model_config.get('two_stage', False)
        args.with_box_refine = model_config.get('with_box_refine', False)
        
        # Loss
        args.aux_loss = model_config.get('aux_loss', True)
        loss_weights = model_config.get('loss_weights', {})
        args.cls_loss_coef = loss_weights.get('class_loss_coef', 2.0)
        args.bbox_loss_coef = loss_weights.get('bbox_loss_coef', 5.0)
        args.giou_loss_coef = loss_weights.get('giou_loss_coef', 2.0)
        args.focal_alpha = loss_weights.get('focal_alpha', 0.25)
        
        # Matcher
        args.set_cost_class = model_config.get('set_cost_class', 2.0)
        args.set_cost_bbox = model_config.get('set_cost_bbox', 5.0)
        args.set_cost_giou = model_config.get('set_cost_giou', 2.0)
        
        # å…¶ä»–
        args.num_classes = num_classes
        
        return args
    
    def forward(self, pixel_values=None, pixel_mask=None, labels=None, samples=None, targets=None):
        """
        å‰å‘ä¼ æ’­ - å…¼å®¹ HuggingFace å’Œå®˜æ–¹æ¥å£
        
        Args:
            pixel_values: [HF é£æ ¼] å›¾åƒå¼ é‡ (batch_size, 3, H, W)
            pixel_mask: [HF é£æ ¼] æ©ç å¼ é‡ (batch_size, H, W)
            labels: [HF é£æ ¼] æ ‡ç­¾åˆ—è¡¨ï¼ŒåŒ…å« 'class_labels' å’Œ 'boxes'
            samples: [å®˜æ–¹é£æ ¼] NestedTensor æˆ–å›¾åƒåˆ—è¡¨
            targets: [å®˜æ–¹é£æ ¼] æ ‡ç­¾åˆ—è¡¨ï¼ŒåŒ…å« 'labels' å’Œ 'boxes'
        
        Returns:
            å¦‚æœæä¾›æ ‡ç­¾ï¼Œè¿”å›åŒ…å« loss çš„è¾“å‡ºå¯¹è±¡
            å¦åˆ™è¿”å›é¢„æµ‹ç»“æœå­—å…¸
        """
        # è·å–å¿…è¦çš„ç±»
        modules = _lazy_import_deformable_detr()
        NestedTensor = modules['NestedTensor']
        nested_tensor_from_tensor_list = modules['nested_tensor_from_tensor_list']
        
        # å‚æ•°è½¬æ¢ï¼šHF é£æ ¼ -> å®˜æ–¹é£æ ¼
        if pixel_values is not None:
            # HF æ¥å£ï¼šæ„é€  NestedTensor
            if pixel_mask is None:
                # å¦‚æœæ²¡æœ‰æä¾› maskï¼Œåˆ›å»ºå…¨ 1 mask
                pixel_mask = torch.ones((pixel_values.shape[0], pixel_values.shape[2], pixel_values.shape[3]),
                                       dtype=torch.bool, device=pixel_values.device)
            
            samples = NestedTensor(pixel_values, pixel_mask)
            
            # æ ‡ç­¾å­—æ®µæ˜ å°„ï¼šclass_labels -> labels
            if labels is not None:
                targets = []
                for item in labels:
                    target = {}
                    # HF ä½¿ç”¨ 'class_labels'ï¼Œå®˜æ–¹ä½¿ç”¨ 'labels'
                    if 'class_labels' in item:
                        target['labels'] = item['class_labels']
                    elif 'labels' in item:
                        target['labels'] = item['labels']
                    
                    # boxes å­—æ®µä¿æŒä¸å˜
                    if 'boxes' in item:
                        target['boxes'] = item['boxes']
                    
                    targets.append(target)
        
        elif samples is None:
            raise ValueError("å¿…é¡»æä¾› pixel_values æˆ– samples å‚æ•°")
        
        # ç¡®ä¿è¾“å…¥æ˜¯ NestedTensor æ ¼å¼
        if not isinstance(samples, NestedTensor):
            samples = nested_tensor_from_tensor_list(samples)
        
        # æ¨¡å‹å‰å‘ä¼ æ’­
        outputs = self.model(samples)
        
        if targets is not None:
            # è®­ç»ƒæ¨¡å¼ï¼šè®¡ç®—æŸå¤±
            loss_dict = self.criterion(outputs, targets)
            weight_dict = self.criterion.weight_dict
            
            # åŠ æƒæŸå¤±
            losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)
            
            # è¿”å›æ ¼å¼ä¸ HF DETR ä¸€è‡´
            return type('Outputs', (), {
                'loss': losses,
                'loss_dict': loss_dict,
                'logits': outputs['pred_logits'],
                'pred_boxes': outputs['pred_boxes'],
            })()
        else:
            # æ¨ç†æ¨¡å¼ï¼šè¿”å›å®˜æ–¹æ ¼å¼ï¼ˆä¸ HF ä¸åŒï¼‰
            return outputs


def build_deformable_detr_model(config: dict) -> nn.Module:
    """
    æ„å»º Deformable DETR æ¨¡å‹
    
    Args:
        config: é…ç½®å­—å…¸
    
    Returns:
        DeformableDETRModel å®ä¾‹
    """
    return DeformableDETRModel(config)


def post_process_deformable_detr(outputs, target_sizes, threshold=0.7):
    """
    Deformable DETR åå¤„ç†å‡½æ•°
    å°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸º COCO æ ¼å¼çš„æ£€æµ‹ç»“æœ
    
    Args:
        outputs: æ¨¡å‹è¾“å‡ºå­—å…¸ï¼ŒåŒ…å« 'pred_logits' å’Œ 'pred_boxes'
        target_sizes: ç›®æ ‡å°ºå¯¸å¼ é‡ (batch_size, 2) [height, width]
        threshold: ç½®ä¿¡åº¦é˜ˆå€¼
    
    Returns:
        List[Dict]: æ¯å¼ å›¾åƒçš„æ£€æµ‹ç»“æœï¼Œæ ¼å¼ä¸ HF åå¤„ç†ä¸€è‡´
            - scores: ç½®ä¿¡åº¦åˆ—è¡¨
            - labels: ç±»åˆ« ID åˆ—è¡¨
            - boxes: è¾¹ç•Œæ¡†åˆ—è¡¨ (xyxy æ ¼å¼)
    """
    import torch.nn.functional as F
    
    # è·å–é¢„æµ‹
    logits = outputs['pred_logits']  # (batch_size, num_queries, num_classes)
    boxes = outputs['pred_boxes']    # (batch_size, num_queries, 4) å½’ä¸€åŒ–çš„ cxcywh
    
    # Softmax è·å–ç±»åˆ«æ¦‚ç‡
    prob = F.softmax(logits, -1)
    
    # è·å–æœ€å¤§æ¦‚ç‡å’Œå¯¹åº”ç±»åˆ«ï¼ˆæ’é™¤èƒŒæ™¯ç±»ï¼‰
    scores, labels = prob[..., :-1].max(-1)
    
    # è½¬æ¢ boxes ä» cxcywh å½’ä¸€åŒ–æ ¼å¼åˆ° xyxy åƒç´ æ ¼å¼
    # cxcywh -> xyxy
    boxes_xyxy = torch.zeros_like(boxes)
    boxes_xyxy[..., 0] = boxes[..., 0] - boxes[..., 2] / 2  # x1 = cx - w/2
    boxes_xyxy[..., 1] = boxes[..., 1] - boxes[..., 3] / 2  # y1 = cy - h/2
    boxes_xyxy[..., 2] = boxes[..., 0] + boxes[..., 2] / 2  # x2 = cx + w/2
    boxes_xyxy[..., 3] = boxes[..., 1] + boxes[..., 3] / 2  # y2 = cy + h/2
    
    # ç¼©æ”¾åˆ°ç›®æ ‡å°ºå¯¸
    img_h, img_w = target_sizes.unbind(1)
    scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1)
    boxes_xyxy = boxes_xyxy * scale_fct[:, None, :]
    
    # è¿‡æ»¤ä½ç½®ä¿¡åº¦é¢„æµ‹
    results = []
    for s, l, b in zip(scores, labels, boxes_xyxy):
        # åº”ç”¨é˜ˆå€¼
        keep = s > threshold
        
        results.append({
            'scores': s[keep],
            'labels': l[keep],
            'boxes': b[keep],
        })
    
    return results
