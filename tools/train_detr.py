#!/usr/bin/env python3
"""
DETR è®­ç»ƒè„šæœ¬
æ”¯æŒä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°ï¼Œè¿›è¡Œäº¤é€šåœºæ™¯ç›®æ ‡æ£€æµ‹è®­ç»ƒ
"""

import argparse
import os
import sys
import time
from pathlib import Path

import torch
import yaml
from tqdm import tqdm
from pycocotools.coco import COCO
from transformers import DetrImageProcessor

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dataset import build_dataloader
from models import build_detr_model
from utils import MetricsLogger, save_checkpoint, setup_logger
from tools.eval_detr import evaluate


def load_config(config_path: str) -> dict:
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def setup_output_dir(config: dict, args) -> Path:
    """è®¾ç½®è¾“å‡ºç›®å½•"""
    if args.output_dir:
        output_dir = Path(args.output_dir)
    else:
        base_dir = config['output']['base_dir']
        exp_name = config['output']['experiment_name']
        output_dir = Path(base_dir) / exp_name
    
    output_dir.mkdir(parents=True, exist_ok=True)
    return output_dir


def save_config(config: dict, output_dir: Path):
    """ä¿å­˜é…ç½®åˆ°è¾“å‡ºç›®å½•"""
    config_save_path = output_dir / "config.yaml"
    with open(config_save_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False)
    print(f"ğŸ’¾ é…ç½®å·²ä¿å­˜: {config_save_path}")


def train_one_epoch(
    model,
    dataloader,
    optimizer,
    device,
    epoch,
    image_processor,
    max_iters,
    log_interval,
    logger,
):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    
    epoch_loss = 0.0
    num_batches = 0
    
    pbar = tqdm(dataloader, desc=f"Epoch {epoch}")
    
    for batch_idx, (images, targets) in enumerate(pbar):
        # ä½¿ç”¨DetrImageProcessorå¤„ç†å¯å˜å°ºå¯¸å›¾åƒï¼ˆè‡ªåŠ¨paddingå¹¶ç”Ÿæˆpixel_maskï¼‰
        # å°†Tensoråˆ—è¡¨è½¬ä¸ºPIL/numpyæ ¼å¼ä»¥ä¾›processorå¤„ç†
        images_pil = [img.cpu().numpy().transpose(1, 2, 0) for img in images]
        
        # processorä¼šè‡ªåŠ¨paddingåˆ°æœ€å¤§å°ºå¯¸å¹¶è¿”å›pixel_valueså’Œpixel_mask
        encoding = image_processor(
            images=images_pil,
            annotations=[{'boxes': t['boxes'].tolist(), 'labels': t['labels'].tolist()} for t in targets],
            return_tensors='pt'
        )
        
        # ç§»åˆ°è®¾å¤‡
        pixel_values = encoding['pixel_values'].to(device)
        pixel_mask = encoding['pixel_mask'].to(device)
        
        # é‡æ„targetsï¼ˆprocessorå¯èƒ½é‡æ–°æ’åº/å½’ä¸€åŒ–boxesï¼‰
        targets = [{k: v.to(device) if isinstance(v, torch.Tensor) else v 
                   for k, v in t.items()} for t in targets]
        
        # å‰å‘ä¼ æ’­
        outputs = model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=targets)
        
        # è®¡ç®—loss
        loss = outputs.loss
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        
        # æ¢¯åº¦è£å‰ªï¼ˆå¯é€‰ï¼‰
        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)
        
        optimizer.step()
        
        # è®°å½•
        epoch_loss += loss.item()
        num_batches += 1
        
        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({
            'loss': f"{loss.item():.4f}",
            'avg_loss': f"{epoch_loss / num_batches:.4f}"
        })
        
        # æ—¥å¿—è¾“å‡º
        if (batch_idx + 1) % log_interval == 0:
            logger.info(
                f"Epoch [{epoch}] Iter [{batch_idx + 1}/{len(dataloader)}] "
                f"Loss: {loss.item():.4f} Avg Loss: {epoch_loss / num_batches:.4f}"
            )
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£
        if max_iters and num_batches >= max_iters:
            logger.info(f"è¾¾åˆ°æœ€å¤§è¿­ä»£æ•° {max_iters}ï¼Œåœæ­¢è®­ç»ƒ")
            break
    
    return epoch_loss / num_batches if num_batches > 0 else 0.0


def train(config: dict, args):
    """
    è®­ç»ƒä¸»å‡½æ•°
    """
    print("\n" + "="*60)
    print("ğŸš€ å¼€å§‹è®­ç»ƒ DETR æ¨¡å‹")
    print("="*60)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device(config['device']['type'] if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ”§ è®¾å¤‡: {device}")
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print(f"\nğŸ“‹ è®­ç»ƒé…ç½®:")
    print(f"  æ•°æ®é›†: {config['dataset']['name']}")
    print(f"  ç±»åˆ«æ•°: {config['dataset']['num_classes']}")
    print(f"  æ¨¡å‹: {config['model']['name']}")
    print(f"  Batch Size: {config['training']['batch_size']}")
    print(f"  Max Epochs: {config['training']['max_epochs']}")
    print(f"  å­¦ä¹ ç‡: {config['training']['optimizer']['lr']}")
    
    if args.max_iter:
        print(f"  æœ€å¤§è¿­ä»£: {args.max_iter}")
        config['training']['max_iters'] = args.max_iter
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = setup_output_dir(config, args)
    print(f"  è¾“å‡ºç›®å½•: {output_dir}")
    
    # ä¿å­˜é…ç½®
    save_config(config, output_dir)
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logger('train', output_dir / 'train.log')
    metrics_logger = MetricsLogger(output_dir)
    
    # æ„å»ºæ•°æ®åŠ è½½å™¨
    print("\n" + "="*60)
    print("ğŸ“¦ æ„å»ºæ•°æ®åŠ è½½å™¨")
    print("="*60)
    
    train_loader = build_dataloader(config, 'train')
    val_loader = build_dataloader(config, 'val')
    
    # æ„å»ºæ¨¡å‹
    print("\n" + "="*60)
    print("ğŸ—ï¸  æ„å»ºæ¨¡å‹")
    print("="*60)
    
    model = build_detr_model(config)
    model = model.to(device)
    
    # åˆå§‹åŒ–å›¾åƒå¤„ç†å™¨ï¼ˆç”¨äºå¯å˜å°ºå¯¸paddingï¼‰
    image_processor = DetrImageProcessor.from_pretrained(config['model']['name'])
    
    # æ„å»ºä¼˜åŒ–å™¨
    print("\nğŸ“Š æ„å»ºä¼˜åŒ–å™¨")
    optimizer_config = config['training']['optimizer']
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=optimizer_config['lr'],
        weight_decay=optimizer_config['weight_decay'],
        betas=optimizer_config['betas'],
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.StepLR(
        optimizer,
        step_size=config['training']['lr_scheduler']['step_size'],
        gamma=config['training']['lr_scheduler']['gamma'],
    )
    
    # è®­ç»ƒå¾ªç¯
    print("\n" + "="*60)
    print("ğŸ¯ å¼€å§‹è®­ç»ƒ")
    print("="*60)
    
    max_epochs = config['training']['max_epochs']
    max_iters = config['training'].get('max_iters')
    log_interval = config['training']['log_interval']
    save_interval = config['training']['save_interval']
    eval_interval = config['training'].get('eval_interval', 5)  # é»˜è®¤æ¯5ä¸ªepochéªŒè¯ä¸€æ¬¡
    
    # åŠ è½½COCO ground truthç”¨äºéªŒè¯
    root_dir = Path(config['dataset']['root_dir'])
    val_ann_file = root_dir / config['dataset']['val_ann']
    coco_gt = COCO(val_ann_file)
    
    best_loss = float('inf')
    best_map = 0.0
    start_time = time.time()
    
    for epoch in range(1, max_epochs + 1):
        logger.info(f"\n{'='*60}")
        logger.info(f"Epoch {epoch}/{max_epochs}")
        logger.info(f"{'='*60}")
        
        # è®­ç»ƒä¸€ä¸ªepoch
        avg_loss = train_one_epoch(
            model=model,
            dataloader=train_loader,
            optimizer=optimizer,
            device=device,
            epoch=epoch,
            image_processor=image_processor,
            max_iters=max_iters,
            log_interval=log_interval,
            logger=logger,
        )
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        current_lr = optimizer.param_groups[0]['lr']
        
        # éªŒè¯ï¼ˆå®šæœŸè¿›è¡Œï¼‰
        val_metrics = {}
        if epoch % eval_interval == 0:
            logger.info(f"\n{'='*60}")
            logger.info("å¼€å§‹éªŒè¯...")
            logger.info(f"{'='*60}")
            val_metrics = evaluate(
                model=model,
                dataloader=val_loader,
                device=device,
                coco_gt=coco_gt,
                logger=logger,
                score_threshold=0.05,
                image_processor=image_processor,
            )
            logger.info(f"éªŒè¯ç»“æœ: mAP={val_metrics.get('mAP', 0):.4f}, "
                       f"mAP@50={val_metrics.get('mAP_50', 0):.4f}, "
                       f"mAP@75={val_metrics.get('mAP_75', 0):.4f}")
        
        # è®°å½•æŒ‡æ ‡
        metrics = {
            'loss': avg_loss,
            'lr': current_lr,
        }
        metrics.update(val_metrics)  # æ·»åŠ éªŒè¯æŒ‡æ ‡
        
        metrics_logger.log(metrics, step=epoch, epoch=epoch)
        
        logger.info(f"Epoch {epoch} å®Œæˆ - Avg Loss: {avg_loss:.4f}, LR: {current_lr:.6f}")
        
        # ä¿å­˜checkpoint
        if epoch % save_interval == 0:
            save_checkpoint(
                model=model,
                optimizer=optimizer,
                epoch=epoch,
                step=epoch * len(train_loader),
                metrics=metrics,
                output_dir=output_dir,
                filename=f"checkpoint_epoch_{epoch}.pth",
            )
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºéªŒè¯mAPï¼Œå¦‚æœæ²¡æœ‰éªŒè¯åˆ™ä½¿ç”¨è®­ç»ƒlossï¼‰
        current_map = val_metrics.get('mAP', 0)
        if current_map > 0:  # æœ‰éªŒè¯ç»“æœæ—¶ä½¿ç”¨mAP
            if current_map > best_map:
                best_map = current_map
                logger.info(f"ğŸ‰ æ–°çš„æœ€ä½³mAP: {best_map:.4f}")
                save_checkpoint(
                    model=model,
                    optimizer=optimizer,
                    epoch=epoch,
                    step=epoch * len(train_loader),
                    metrics=metrics,
                    output_dir=output_dir,
                    filename="best.pth",
                    is_best=True,
                )
        else:  # æ²¡æœ‰éªŒè¯æ—¶ä½¿ç”¨è®­ç»ƒloss
            if avg_loss < best_loss:
                best_loss = avg_loss
                logger.info(f"ğŸ‰ æ–°çš„æœ€ä½³Loss: {best_loss:.4f}")
                save_checkpoint(
                    model=model,
                    optimizer=optimizer,
                    epoch=epoch,
                    step=epoch * len(train_loader),
                    metrics=metrics,
                    output_dir=output_dir,
                    filename="best.pth",
                    is_best=True,
                )
        
        # å¦‚æœè®¾ç½®äº†max_itersä¸”å·²è¾¾åˆ°é¢„æœŸepochæ•°ï¼Œåœæ­¢è®­ç»ƒ
        # æ³¨æ„ï¼šåªæœ‰åœ¨max_iterså¾ˆå°æ—¶æ‰æå‰åœæ­¢ï¼ˆçœŸæ­£çš„å†’çƒŸæµ‹è¯•ï¼‰
        if max_iters and max_iters <= 200 and epoch >= 2:
            logger.info(f"å†’çƒŸæµ‹è¯•æ¨¡å¼ï¼šå·²å®Œæˆ {epoch} ä¸ªepochï¼Œåœæ­¢è®­ç»ƒ")
            break
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    save_checkpoint(
        model=model,
        optimizer=optimizer,
        epoch=epoch,
        step=epoch * len(train_loader),
        metrics=metrics,
        output_dir=output_dir,
        filename="last.pth",
    )
    
    elapsed_time = time.time() - start_time
    logger.info(f"\n{'='*60}")
    logger.info(f"âœ… è®­ç»ƒå®Œæˆï¼")
    logger.info(f"   æ€»è€—æ—¶: {elapsed_time / 60:.2f} åˆ†é’Ÿ")
    logger.info(f"   æœ€ä½³Loss: {best_loss:.4f}")
    logger.info(f"   è¾“å‡ºç›®å½•: {output_dir}")
    logger.info(f"{'='*60}\n")
    
    print("\n" + "="*60)
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    print(f"   æ€»è€—æ—¶: {elapsed_time / 60:.2f} åˆ†é’Ÿ")
    print(f"   æœ€ä½³Loss: {best_loss:.4f}")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    print("="*60)


def main():
    parser = argparse.ArgumentParser(
        description="è®­ç»ƒDETRæ¨¡å‹ç”¨äºäº¤é€šåœºæ™¯ç›®æ ‡æ£€æµ‹"
    )
    parser.add_argument(
        "--config",
        type=str,
        default="configs/detr_baseline.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help="è¾“å‡ºç›®å½•ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ï¼‰",
    )
    parser.add_argument(
        "--max-iter",
        type=int,
        default=None,
        help="æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆç”¨äºå†’çƒŸæµ‹è¯•ï¼‰",
    )
    parser.add_argument(
        "--eval-interval",
        type=int,
        default=None,
        help="è¯„ä¼°é—´éš”",
    )
    parser.add_argument(
        "--save-interval",
        type=int,
        default=None,
        help="ä¿å­˜é—´éš”",
    )
    parser.add_argument(
        "--resume",
        type=str,
        default=None,
        help="ä»checkpointæ¢å¤è®­ç»ƒ",
    )
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    print(f"ğŸ“– åŠ è½½é…ç½®æ–‡ä»¶: {args.config}")
    config = load_config(args.config)
    
    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.max_iter:
        config['training']['max_iters'] = args.max_iter
    if args.eval_interval:
        config['training']['eval_interval'] = args.eval_interval
    if args.save_interval:
        config['training']['save_interval'] = args.save_interval
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = setup_output_dir(config, args)
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    
    # ä¿å­˜é…ç½®
    save_config(config, output_dir)
    
    # å¼€å§‹è®­ç»ƒ
    train(config, args)


if __name__ == "__main__":
    main()
