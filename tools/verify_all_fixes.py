#!/usr/bin/env python3
"""
å®Œæ•´éªŒè¯ï¼šæ£€æŸ¥ç¬¬äºŒè½®å…³é”®ä¿®å¤
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

def check_imports():
    """æ£€æŸ¥å…³é”®å¯¼å…¥"""
    print("=" * 80)
    print("1. æ£€æŸ¥å¯¼å…¥")
    print("=" * 80)
    
    try:
        from tools.train_detr_optimized import CocoDetrDataset, DETR_MEAN, DETR_STD
        print("âœ… train_detr_optimized.py å¯å¯¼å…¥")
        print(f"   DETR_MEAN: {DETR_MEAN}")
        print(f"   DETR_STD: {DETR_STD}")
    except Exception as e:
        print(f"âŒ train_detr_optimized.py å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from tools.benchmark_dataloader import benchmark_dataloader
        print("âœ… benchmark_dataloader.py å¯å¯¼å…¥")
    except Exception as e:
        print(f"âŒ benchmark_dataloader.py å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True


def check_dataset_mapping():
    """æ£€æŸ¥ Category ID æ˜ å°„"""
    print("\n" + "=" * 80)
    print("2. æ£€æŸ¥ Category ID æ˜ å°„")
    print("=" * 80)
    
    try:
        from tools.train_detr_optimized import CocoDetrDataset
        from pycocotools.coco import COCO
        
        ann_file = "data/traffic_coco/bdd100k_det/annotations/instances_train.json"
        if not Path(ann_file).exists():
            print(f"âš ï¸  æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {ann_file}")
            return True  # è·³è¿‡ï¼Œä¸ç®—å¤±è´¥
        
        coco = COCO(ann_file)
        cat_ids = sorted(coco.getCatIds())
        
        print(f"åŸå§‹ category_id: {cat_ids}")
        
        # æ£€æŸ¥æ˜¯å¦è¿ç»­
        is_continuous = cat_ids == list(range(len(cat_ids)))
        if is_continuous:
            print("âœ… Category ID å·²ç»è¿ç»­ï¼Œæ˜ å°„ä¸ºæ’ç­‰æ˜ å°„")
        else:
            print(f"âš ï¸  Category ID ä¸è¿ç»­ï¼Œéœ€è¦æ˜ å°„")
        
        # åˆ›å»º dataset æ£€æŸ¥æ˜ å°„
        ds = CocoDetrDataset(
            "data/traffic_coco/bdd100k_det/images/train",
            ann_file,
            min_size=800,
            max_size=1333
        )
        
        print(f"æ˜ å°„å ID: {list(range(ds.num_classes))}")
        print(f"åå‘æ˜ å°„: {ds.reverse_cat_id_map}")
        
        # éªŒè¯åå‘æ˜ å°„
        for i in range(ds.num_classes):
            original = ds.reverse_cat_id_map[i]
            if original != cat_ids[i]:
                print(f"âŒ åå‘æ˜ å°„é”™è¯¯: {i} -> {original}, æœŸæœ› {cat_ids[i]}")
                return False
        
        print("âœ… Category ID æ˜ å°„æ­£ç¡®")
        return True
        
    except Exception as e:
        print(f"âŒ Category ID æ˜ å°„æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def check_bbox_format():
    """æ£€æŸ¥ Bbox æ ¼å¼"""
    print("\n" + "=" * 80)
    print("3. æ£€æŸ¥ Bbox æ ¼å¼")
    print("=" * 80)
    
    try:
        from tools.train_detr_optimized import CocoDetrDataset
        import torch
        
        ann_file = "data/traffic_coco/bdd100k_det/annotations/instances_train.json"
        if not Path(ann_file).exists():
            print(f"âš ï¸  æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {ann_file}")
            return True
        
        ds = CocoDetrDataset(
            "data/traffic_coco/bdd100k_det/images/train",
            ann_file,
            min_size=800,
            max_size=1333
        )
        
        # æ£€æŸ¥ç¬¬ä¸€å¼ å›¾
        img, target = ds[0]
        
        print(f"å›¾åƒå½¢çŠ¶: {img.shape}")
        print(f"orig_size: {target['orig_size'].tolist()}")
        print(f"size: {target['size'].tolist()}")
        
        if len(target['boxes']) > 0:
            boxes = target['boxes']
            print(f"Boxes å½¢çŠ¶: {boxes.shape}")
            print(f"Boxes èŒƒå›´: [{boxes.min():.3f}, {boxes.max():.3f}]")
            
            # æ£€æŸ¥å½’ä¸€åŒ–
            if boxes.min() < 0 or boxes.max() > 1:
                print(f"âŒ Boxes æœªæ­£ç¡®å½’ä¸€åŒ–åˆ° [0, 1]")
                return False
            
            print("âœ… Boxes æ ¼å¼æ­£ç¡®ï¼ˆå½’ä¸€åŒ– cxcywhï¼‰")
        else:
            print("âš ï¸  ç¬¬ä¸€å¼ å›¾æ²¡æœ‰æ ‡æ³¨æ¡†")
        
        return True
        
    except Exception as e:
        print(f"âŒ Bbox æ ¼å¼æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def check_target_sizes():
    """æ£€æŸ¥ orig_size vs size"""
    print("\n" + "=" * 80)
    print("4. æ£€æŸ¥åæ ‡ç³»ï¼ˆorig_size vs sizeï¼‰")
    print("=" * 80)
    
    try:
        from tools.train_detr_optimized import CocoDetrDataset
        
        ann_file = "data/traffic_coco/bdd100k_det/annotations/instances_train.json"
        if not Path(ann_file).exists():
            print(f"âš ï¸  æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {ann_file}")
            return True
        
        ds = CocoDetrDataset(
            "data/traffic_coco/bdd100k_det/images/train",
            ann_file,
            min_size=800,
            max_size=1333
        )
        
        img, target = ds[0]
        orig_h, orig_w = target['orig_size'].tolist()
        new_h, new_w = target['size'].tolist()
        
        print(f"åŸå§‹å°ºå¯¸: {orig_h} x {orig_w}")
        print(f"Resizeå: {new_h} x {new_w}")
        
        # æ£€æŸ¥æ˜¯å¦ä¸åŒ
        if orig_h == new_h and orig_w == new_w:
            print("âš ï¸  orig_size == sizeï¼ˆå¯èƒ½æ²¡æœ‰ resizeï¼‰")
        else:
            print("âœ… orig_size != sizeï¼ˆæ­£ç¡®ä¿å­˜äº†åŸå§‹å°ºå¯¸ï¼‰")
        
        # æ£€æŸ¥ evaluate() å‡½æ•°æºç 
        import inspect
        from tools.train_detr_optimized import evaluate
        source = inspect.getsource(evaluate)
        
        if "orig_size" in source and "target_sizes" in source:
            # æŸ¥æ‰¾ target_sizes èµ‹å€¼
            if 'target_sizes = torch.stack([l["orig_size"]' in source:
                print("âœ… evaluate() æ­£ç¡®ä½¿ç”¨ orig_size ä½œä¸º target_sizes")
            elif 'target_sizes = torch.stack([l["size"]' in source:
                print("âŒ evaluate() é”™è¯¯ä½¿ç”¨ size ä½œä¸º target_sizesï¼ˆåº”è¯¥ç”¨ orig_sizeï¼‰")
                return False
            else:
                print("âš ï¸  æ— æ³•ç¡®è®¤ target_sizes èµ‹å€¼")
        else:
            print("âŒ evaluate() å¯èƒ½æœªæ­£ç¡®ä½¿ç”¨ orig_size")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ åæ ‡ç³»æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def check_files():
    """æ£€æŸ¥æ–‡ä»¶çŠ¶æ€"""
    print("\n" + "=" * 80)
    print("5. æ£€æŸ¥æ–‡ä»¶çŠ¶æ€")
    print("=" * 80)
    
    files = {
        "âœ… å¯ç”¨": [
            "tools/train_detr_optimized.py",
            "tools/benchmark_dataloader.py",
            "tools/run_torchvision_training.sh",
            "docs/DETR_TRAINING_GUIDE_CURRENT.md",
            "docs/DETR_TRAINING_README.md",
            "docs/FIXES_2026_01_06.md",
        ],
        "âŒ å·²æ ‡è®°ä¸å¯ç”¨": [
            "tools/train_detr_torchvision.py.BROKEN",
            "tools/smoke_test_torchvision.py.BROKEN",
        ],
        "ğŸ“„ å·²è¿‡æ—¶": [
            "docs/TORCHVISION_DETR_GUIDE.md.OUTDATED",
            "docs/TORCHVISION_DETR_SUMMARY.md.OUTDATED",
        ]
    }
    
    all_ok = True
    for category, paths in files.items():
        print(f"\n{category}:")
        for path in paths:
            exists = Path(path).exists()
            status = "âœ“" if exists else "âœ—"
            print(f"  [{status}] {path}")
            if not exists and "å¯ç”¨" in category:
                all_ok = False
    
    return all_ok


def main():
    """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
    print("\nğŸ” DETR è®­ç»ƒè„šæœ¬éªŒè¯")
    print("æ£€æŸ¥æ‰€æœ‰å…³é”®ä¿®å¤æ˜¯å¦æ­£ç¡®\n")
    
    checks = [
        ("å¯¼å…¥æ£€æŸ¥", check_imports),
        ("Category ID æ˜ å°„", check_dataset_mapping),
        ("Bbox æ ¼å¼", check_bbox_format),
        ("åæ ‡ç³»ï¼ˆorig_size vs sizeï¼‰", check_target_sizes),
        ("æ–‡ä»¶çŠ¶æ€", check_files),
    ]
    
    results = []
    for name, func in checks:
        try:
            result = func()
            results.append((name, result))
        except Exception as e:
            print(f"\nâŒ {name} æ£€æŸ¥å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("éªŒè¯æ€»ç»“")
    print("=" * 80)
    
    for name, result in results:
        status = "âœ…" if result else "âŒ"
        print(f"{status} {name}")
    
    all_passed = all(r for _, r in results)
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼è„šæœ¬å·²å‡†å¤‡å°±ç»ªã€‚")
        print("\nä¸‹ä¸€æ­¥ï¼šè¿è¡Œå†’çƒŸæµ‹è¯•")
        print("  python tools/train_detr_optimized.py \\")
        print("    --train-img data/traffic_coco/bdd100k_det/images/train \\")
        print("    --train-ann data/traffic_coco/bdd100k_det/annotations/instances_train.json \\")
        print("    --subset 100 --num-epochs 1 --batch-size 4")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ£€æŸ¥å¤±è´¥ï¼Œè¯·æŸ¥çœ‹ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")
        return 1


if __name__ == "__main__":
    sys.exit(main())
